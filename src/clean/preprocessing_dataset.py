import pandas as pd
import numpy as np

import re #for SalesDataCleaner class
import os
from typing import List
from typing import Dict

# from pandas_profiling import ProfileReport

pd.options.display.max_rows = 20
pd.options.display.max_columns = None



"""DEFAULT VALUES SETUP"""
"""Scrapping cleaning"""
COLUMNS_DROP = [] #'hyperlink', 'land_plot_surface', 'sale']
COLUMNS_CONVERTERS = {
            # read_csv has issue with None in Boolean (interpreted as object). I am using "kitchen_has": lambda x: bool(x) if type(x) is bool else Non
            'kitchen_has': lambda x: SalesDataCleaner.bool_or_keep(x),
            'furnished': lambda x: SalesDataCleaner.bool_or_keep(x),
            'open_fire': lambda x: SalesDataCleaner.bool_or_keep(x),
            'terrace': lambda x: SalesDataCleaner.bool_or_keep(x),
            'garden': lambda x: SalesDataCleaner.bool_or_keep(x),
            'swimming_pool_has': lambda x: SalesDataCleaner.bool_or_keep(x),
            'terrace_area': lambda x: SalesDataCleaner.float_or_zero(x),
            'land_plot_surface': lambda x: SalesDataCleaner.float_or_text_to_nan(x),
            'area': lambda x: SalesDataCleaner.area_remove_m2(x),
            'price': lambda x: SalesDataCleaner.price_converter(x)
        }

"""Preprocessing cleaning"""
#FM 8/12/20 filepaths moved to models_creation.py

# for terrace and garden it will be double checked if their related boolean is True when area is 0
COLUMNS_NAN_REPLACE_WITH = {"terrace_area": 0, "garden_area": 0, "facades_number": 0}
# for outliers detection Tukey fences are used instead of percentile due to not normal distribution
OUTLIERS_METHODS = ["fence_tukey_min", "fence_tukey_max"]  # , "5%", "95%"]
# numerical categorical columns are excluded from outliers analysis
# boolean (onlt two distinct values) are excluded automatically as not being np.numeric
# columns with prevalent nan values (previously filled with zero) excluded:
# garden_area, terrace_area, land_surface, facades_number
COLUMNS_OUTLIERS_IGNORE = ["facades_number", "garden_area", "postcode", "src", "terrace_area", "land_surface",
                           "price_m_by_postcode", "latitude", "longitude"]
# during the profiling dominant values found in equipped kitchen (true, 83.7%), furnished (False, 96.3%), Open Fire (False, 93.5%)
# columns with a dominant value (inc. src and swimming pool) are excluded from duplicates check.
# related boolean columns (e.g. garden_has) are also excluded.
# region is excluded having already postcode
# building_state_agg is excluded since aggregation of different approaches from different sources.
# more info in previous project repository https://github.com/FrancescoMariottini/residential-real-estate-analysis/blob/main/README.md
COLUMNS_DUPLICATES_CHECK = ["postcode", "house_is", "property_subtype", "price", "rooms_number", "area"]
# aggregation for median price was based on related available official statistics (statbel)
# building_state_agg not available in statbel but could maybe retrieved in a different way
# e.g. distinction between old and new buildings
COLUMNS_GROUPED_BY = {"facades_number": "property_subtype"} #not neeeded by Ankita: "price":"property_subtype", "price":"region"}  "price":"building_state_agg"}
COLUMNS_TO_REPLACE = ["facades_number"]
GROUPBY_AGGREGATORS = [np.median]  # [min,max,np.mean,np.median,len]
AGGREGATOR_COLUMNS = {min: "min", max: "max", np.mean: "mean", np.median: "median", len: "len"}
#FM 7/12/20 defining allowed model subtypes
MODEL_SUBTYPES = ["APARTMENT", "HOUSE", "OTHERS"]
OTHER_PROPERTY_SUBTYPES = ["OTHER_PROPERTY", "MIXED_USE_BUILDING"]
RENAME_FOR_DATABASE = {'hyperlink':'id', 'sale': 'building_state_agg'}

DATABASE_COLUMNS = ["id", "postcode", "house_is", "property_subtype", "price", "rooms_number", "area",
                    "equipped_kitchen_has", "furnished", "open_fire", "terrace", "terrace_area", "garden",
                    "garden_area", "land_surface", "facades_number", "swimming_pool_has", "building_state_agg"]
TARGET = "price"
LOG_ON_COLUMNS = ["garden_area", "terrace_area", "land_surface", "area"]
# Not used yet
REPORT_HTML_FILEPATH = os.getcwd() + "\\reports" + "\\df_before_cleaning.html"

class SalesDataCleaner:
    """ Utility class that cleans real estate sale offers data from a CSV file into a pandas DataFrame for further work on it"""

    def __init__(self, sales_data: pd.DataFrame): #url):
        #self.url = url
        self.sales_data = sales_data
        self.cleaned = False

    def get_cleaned_data(self):
        if self.cleaned:
            return self.sales_data.copy()
        else:
            return None

    def write_to_csv(self, filepath):
        if self.cleaned:
            self.sales_data.to_csv(filepath, index=False)

    def clean(self, columns_drop: List[str] = COLUMNS_DROP):
        if not self.cleaned:
            #FM 10/12/20 replaced since drop
            columns_drop = [c for c in columns_drop if c in self.sales_data.columns]
            self.sales_data.drop(columns= columns_drop, inplace= True)
            self.import_and_format()
            # print(self.sales_data.dtypes)
            self.merge_postcodes_localities_columns()
            self.add_region_column()
            #1
            if 'property_subtype' in self.sales_data.columns:
                self.clean_property_subtype_column()
            if 'price' in self.sales_data.columns:
                self.clean_price_column()
            if 'sale' in self.sales_data.columns:
                self.clean_sale_column()
            if 'land_surface' in self.sales_data.columns and 'area' in self.sales_data.columns:
                self.clean_area_land_surface_columns()
            if 'sale' in self.sales_data.columns:
                self.clean_sale_column()
            if 'building_state'in self.sales_data.columns:
                self.clean_building_state_column()
            #if 'facades_number' in self.sales_data.columns: #too many nans removed
            #   self.clean_facades_number_column()

            #self.remove_duplicate_records()
            #self.remove_na_records()

            self.sales_data.rename(columns={"kitchen_has": "equipped_kitchen_has"}, inplace=True)

            # self.display()

            # now that the cleaning is done we update the corresponding binary tag
            self.cleaned = True

    def import_and_format(self, columns_converters = COLUMNS_CONVERTERS):
        # dtypes are assigned for the columns which won't require additional manipulations
        columns_types = {
            'source': int,
            'hyperlink': str,
            'locality': str,
            'postcode': str,
            'house_is': bool,
            'property_subtype': str,
            'sale': str,
            'rooms_number': float,
            'garden_area': float,
            'land_surface': float,
            'facades_number': float,
            'building_state': str
        }

        # transformation functions are assigned for columns which will require additional manipulations

        columns = columns_types.keys()
        # Null string identifiers (discovered iteratively while improving the process) are defined to be replaced by na
        na_identifiers = ['NA', 'None', 'Not specified', 'NaN', 'NAN']
        # The dataset is read while performing at the same time some basic manipulations
        #10/12/20 not necessary
        #self.sales_data = pd.read_csv(self.url, sep=",", dtype=columns_types, skipinitialspace=True,
        #
        #
        columns_in_converters = [c for c in self.sales_data.columns if c in columns_converters]
        for c in columns_in_converters:
            self.sales_data.loc[:, c] = self.sales_data.loc[:, c].apply(columns_converters[c])


    @staticmethod
    def price_converter(x):
            #string manipulation only if needed
            if isinstance(x, str):
                # removing non-digit heading and trailiong characters
                x = re.sub(r'\D+$', '', re.sub(r'^\D+', '', x))
                # removing trailing non-digit and dot characters until the last '€' character
                x = re.sub(r'€(.|\D)*$', '', x)
                x = x.replace(',', '')
                # we expect only digits or a dot after replacing commas with an empty string, so we should be able to convert if
                # if not possible we catch the exceptionproperty_subtype
                try:
                    return float(x)
                except ValueError:
                    return None
            elif isinstance(x, int) or isinstance(x, float) :
                return x


    @staticmethod
    # expected boolean are transformed into bool even if originally were strings or numbers
    def bool_or_keep(x):
        output = None
        try:
            if isinstance(x, bool):
                output = x
            elif isinstance(x, str):
                if (x == '1') or (x.upper() == 'TRUE'):
                    output = True
                elif (x == '0') or (x.upper() == 'FALSE'):
                    output = False
            elif x.isnumeric():
                if x == 1:
                    output = True
                elif x == 0:
                    output = False
            elif isinstance(x, bool):
                output = x
            return output
        except ValueError:
            return None

    @staticmethod
    # expected float values are converted into float even if originally were wrongly coded as boolean or number
    def float_or_zero(x):
        if x is not None:
            try:
                float(x)
                return float(x)
            except ValueError:
                # keeping information of terrace if lost
                if x == True or x == 1 or x == 'True' or x == 'TRUE':
                    return 0
        else:
            return x


    @staticmethod
    # expected float values are returned as None
    def float_or_text_to_nan(x):
        if x is not None:
            try:
                return float(x)
        # generic value error instead of isistance(x,str) to cover more cases instead of strings only.
            except ValueError:
                return None
        elif x is None:
            return None

    @staticmethod
    # a single integer number is extracted from area to remove the m2 measurement units.
    # this simple method was adopted since no commas were found in area field.
    def area_remove_m2(x):
        if x is None or isinstance(x, int):
            return x
        elif isinstance(x, str):
            numbers = [int(s) for s in x.split() if s.isdigit()]
            if len(numbers) == 1:
                return float(numbers[0])
            elif len(numbers) > 1:
                return False
            else:
                return None


    def display(self):
        print(self.sales_data)

    def merge_postcodes_localities_columns(self):
        self.sales_data = self.sales_data.apply(SalesDataCleaner.extract_postcodes, axis='columns')
        self.sales_data.drop('locality', axis='columns', inplace=True)

    @staticmethod
    def extract_postcodes(row):
        if pd.isna(row.postcode):
            legal_belgian_postcode_pattern = '[1-9][0-9][0-9][0-9]'
            extracted_postcodes = re.findall(legal_belgian_postcode_pattern, row.locality)
            if len(extracted_postcodes) > 0:
                row.postcode = extracted_postcodes[0]
            else:
                row.postcode = None
        return row

    def add_region_column(self):
        self.sales_data['region'] = self.sales_data['postcode'].map(SalesDataCleaner.to_region)

    @staticmethod
    def to_region(postcode):
        if pd.isna(postcode):
            region = None
        else:
            # casting: 'str' -> 'int'
            postcode = int(postcode)
            # 'B' -> Brussels-Capital Region
            # 'W' -> Walloon Region
            # 'F' -> Flemish Region
            if 1000 <= postcode and postcode <= 1299:
                region = 'B'
            elif (1300 <= postcode and postcode <= 1499) or (4000 <= postcode and postcode <= 7999):
                region = 'W'
            else:
                region = 'F'
        return region

    def clean_property_subtype_column(self):
        to_be_deleted_subtypes = ['Wohnung', 'Triplexwohnung', 'Sonstige', 'Loft / �tico', 'Loft / Dachgeschoss',
                                  'Loft / Attic',
                                  'Gewerbe', 'Etagenwohnung', 'Erdgeschoss', 'Attico', 'Appartamento duplex',
                                  'Apartamento', 'Altbauwohnung',
                                  'HOUSE_GROUP', 'APARTMENT_GROUP']

        to_be_deleted_filter = self.sales_data['property_subtype'].apply(lambda x: x in to_be_deleted_subtypes)
        self.sales_data.loc[to_be_deleted_filter, 'property_subtype'] = None

        to_be_deleted_filter = self.sales_data['property_subtype'].apply(lambda x: type(x) in [int, float])
        self.sales_data.loc[to_be_deleted_filter, 'property_subtype'] = None

        to_be_deleted_filter = self.sales_data['property_subtype'].apply(lambda x: "sqft" in str(x))
        self.sales_data.loc[to_be_deleted_filter, 'property_subtype'] = None

    def clean_price_column(self):
        to_be_deleted_filter = self.sales_data['price'].apply(lambda x: x == 0.0)
        self.sales_data.loc[to_be_deleted_filter, 'price'] = None

    @staticmethod
    def categorize_state(value):
        to_renovate = ['TO_RENOVATE', 'TO_BE_DONE_UP', 'TO_RESTORE', 'old', 'To renovate', 'To be done up',
                       'To restore']
        good = ['GOOD', 'Good', 'AS_NEW', 'As new']
        renovated = ['JUST_RENOVATED', 'Just renovated']
        new = ['New']
        category = None  # default category (corresponds to values = '0')
        if value in to_renovate:
            category = 'to_renovate'
        elif value in good:
            category = 'good'
        elif value in renovated:
            category = 'renovated'
        elif value in new:
            category = 'new'
        return category

    def clean_building_state_column(self):
        self.sales_data['building_state_agg'] = self.sales_data['building_state'].apply(
            SalesDataCleaner.categorize_state)
        self.sales_data.drop('building_state', axis='columns', inplace=True)

    def clean_sale_column(self):
        to_be_deleted_filter = self.sales_data['sale'].str.contains('annuity', na=False)
        to_delete_index = self.sales_data.index[to_be_deleted_filter]
        self.sales_data.drop(to_delete_index, axis='index', inplace=True)

    def clean_area_column(self):
        to_be_deleted_filter = self.sales_data['area'].apply(lambda x: x == 0.0)
        self.sales_data.loc[to_be_deleted_filter, 'area'] = None

    def clean_area_land_surface_columns(self):
        self.sales_data = self.sales_data.apply(SalesDataCleaner.copy_from_land_surface, axis='columns')

    #def clean_facades_number_column(self): removed
    #    to_be_deleted_filter = self.sales_data['facades_number'].apply(lambda x: x == 0 or x > 4)
    #   self.sales_data.loc[to_be_deleted_filter, 'facades_number'] = None

    @staticmethod
    def copy_from_land_surface(row):
        if row.area == 0.0 and row.land_surface > 0.0:
            row.area = row.land_surface
        return row

    #def remove_duplicate_records(self):
    #    self.sales_data.drop_duplicates(subset=['postcode', 'house_is', 'price', 'area'], inplace=True)

    #def remove_na_records(self):
    #    self.sales_data.dropna(axis=0, inplace=True)




def get_columns_with_nan(df: pd.DataFrame) -> List[str]:
    """
    Obtain columns having at least one nan
    :param df: input table
    :return columns_with_nan:
    """
    columns_with_nan = []
    for c in df.columns:
        c_na_count = df[c].isna().sum()
        if c_na_count > 0:
            columns_with_nan.append(c)
    return columns_with_nan


def describe_with_tukey_fences(df: pd.DataFrame,
                               percentiles: List[float] = [0.95, 0.94, 0.75, 0.5, 0.25, 0.06, 0.05]) -> pd.DataFrame:
    """
    Add tukey fences (for non-normal distribution) to pandas describe method for outliers detection
    :param df: input table
    :param percentiles: percentiles requested
    :return df_desc: description as dataframe including fence_tukey_min and fence_tukey_max
    """
    if 0.25 not in percentiles:
        percentiles.append(0.25)
    if 0.75 not in percentiles:
        percentiles.append(0.75)
    df_desc = df.describe(percentiles, include=np.number)
    df_index = df_desc.index.to_list()
    fence_tukey_min: List = [df_desc.loc["25%", c] - 1.5 * (df_desc.loc["75%", c] - df_desc.loc["25%", c]) for c in
                             df_desc.columns]
    fence_tukey_max: List = [df_desc.loc["75%", c] + 1.5 * (df_desc.loc["75%", c] - df_desc.loc["25%", c]) for c in
                             df_desc.columns]
    df_desc = df_desc.append(dict(zip(df_desc.columns, fence_tukey_min)), ignore_index=True)
    df_desc = df_desc.append(dict(zip(df_desc.columns, fence_tukey_max)), ignore_index=True)
    df_index.append('fence_tukey_min')
    df_index.append('fence_tukey_max')
    df_desc.index = df_index
    return df_desc


def get_outliers_index(df: pd.DataFrame, outliers_methods: List[str] = OUTLIERS_METHODS,
                       columns_outliers_ignore: List[str] = COLUMNS_OUTLIERS_IGNORE) -> pd.DataFrame:
    """
    Identify outliers in a dataframe using tukey and/or percentile fences
    :param df: input table
    :param outliers_methods: from the index of describe_with_tukey_fences() description dataframe
    :param columns_outliers_ignore: numerical columns to be ignored
    :return df_outliers: table with column, method, type, count (of outliers), % (of the rows), first outlier and index (list)
    # type is min or max
    # first outlier is the outlier closest to the accepted values
    """
    df_desc: pd.DataFrame = describe_with_tukey_fences(df)
    columns = [c for c in df_desc.columns if c not in columns_outliers_ignore]
    df_outliers = pd.DataFrame(columns=["column", "method", "type", "count", "%", "first_outlier", "index"])
    for c in columns:
        t_min, t_max, p95, p94, p06, p05 = df_desc.loc[
            ["fence_tukey_min", "fence_tukey_max", "95%", "94%", "6%", "5%"], c]
        for m in outliers_methods:
            # TBC elif (fence_tukey_max < p95) AND (p95 != p94):
            if m == "fence_tukey_min" or m == "5%":
                outliers = df.loc[df[c] < df_desc.loc[m, c], c]
                o_type = 'min'
            elif m == "fence_tukey_max" or m == "95%":
                outliers = df.loc[df[c] > df_desc.loc[m, c], c]
                o_type = 'max'
            index = outliers.index
            if len(index) > 0:
                if o_type == 'min':
                    first_outlier = max(outliers)
                elif o_type == 'max':
                    first_outlier = min(outliers)
                df_outliers = df_outliers.append({"column": c, "method": m, "type": o_type, "count": len(index),
                                                  "%": round(len(index) / len(df) * 100, 2),
                                                  "first_outlier": first_outlier,
                                                  "index": index.tolist()}, ignore_index=True)
    return df_outliers


# 11/12/20 aggreatated used in features engineering
def add_aggregated_columns(df: pd.DataFrame, group_parameters: Dict[str, str] = COLUMNS_GROUPED_BY,
                          groupby_aggregators: List = GROUPBY_AGGREGATORS,
                          columns_to_replace: List[str] = None) -> (pd.DataFrame, List[str]):
    """
    Create aggregated columns to deal with missing values and non-numerical values
    :param df: input table
    :param group_parameters: parameter and column to group for.
    :param groupby_aggregators: aggregate function to use
    :param columns_to_replace: original columns to be replaced with grouped values
    :return df: dataframe with new aggregated columns
    :return column_names: names of added aggregated columns
    """
    aggregated_column_names = []
    for key, value in group_parameters.items():
        df_grp = df.loc[:, [key, value]].dropna(axis=0).groupby(value, as_index=False)[key].agg(groupby_aggregators)
        column_names = [f"{value}_{AGGREGATOR_COLUMNS[aggregator]}_{key}" for aggregator in groupby_aggregators]
        df = df.merge(df_grp, on=value, how='left')
        aggregated_column_names += column_names
        df.rename(columns=dict(zip([AGGREGATOR_COLUMNS[aggregator] for aggregator in groupby_aggregators], column_names)), inplace=True)
    # drop at the end so order in group_parameters not important
    if columns_to_replace is not None:
        df.drop(labels=[c for c in columns_to_replace], axis=1, inplace=True)
        df.rename(columns={'property_subtype_median_facades_number': "facades_number"}, inplace=True) #24/11/20 fast fix
    return df, column_names

class DataCleaning:
    def __init__(self,
                 dataframe: pd.DataFrame,
                 cleaned_csv_path: str = None, #FM 8/12/20 default replaced with None
                 columns_nan_replace_with: Dict[str, int] = COLUMNS_NAN_REPLACE_WITH,
                 columns_duplicates_check: List[str] = COLUMNS_DUPLICATES_CHECK,
                 columns_outliers_ignore: List[str] = COLUMNS_OUTLIERS_IGNORE,
                 outliers_methods: List[str] = OUTLIERS_METHODS,

                 property_subtype: str = None,
                 report_html_filepath: str = REPORT_HTML_FILEPATH, #future release (profiling used for preliminary analysis)
                 ):
        """
        Initialise the dataset cleaning class
        :param columns_nan_replace_with: columns for which nan will be replaced
        :param columns_duplicates_check: columns used as subset for checking duplicates
        :param columns_outliers_ignore: columns for which outliers won't be checked and removed
        :param outliers_methods: see get_outliers_index() method
        :param cleaned_csv_path: path to create the output csv file
        :param report_html_filepath: path to create the pandas_profiling (future release)
        :param: property_subtype: if a specific subtype have to be extracted
        :argument: df_0: original table
        :argument: df_out: modified table
        :argument: columns_with_nan: see fill_na() method
        :argument: index_removed_by_process: store removed indexes through processes
        :argument: outliers: see get_outliers() method
        """
        self.df_0: pd.DataFrame = dataframe #replaced from path
        #FM 8/12/20 mixed used building dealt later
        # if property_subtype is None:
            #FM 8/12/2020 MIXED_USE_BUILDING removed for all cases
            # self.df_0 = self.df_0[self.df_0.property_subtype != "MIXED_USE_BUILDING"]
        if property_subtype is not None:
            self.df_0 = self.df_0[self.df_0.property_subtype == property_subtype]

        self.df_out: pd.DataFrame = self.df_0.copy(deep=True)
        self.columns_with_nan: List[str] = []
        self.index_removed_by_process: Dict[str, List] = {}
        self.outliers = pd.DataFrame(columns=["column", "method", "count", "%", "first_outlier", "index"])
        #FM 8/12/20 transformations recording, time could be added
        self.converters = pd.DataFrame(columns=["column","method","description"])

        self.columns_nan_replace_with = columns_nan_replace_with
        self.columns_duplicates_check = columns_duplicates_check
        self.columns_outliers_ignore = columns_outliers_ignore
        self.outliers_methods = outliers_methods
        self.cleaned_csv_path = cleaned_csv_path

        # not used yet
        #self.report_html_filepath = report_html_filepath

    def fill_na(self, df_before: pd.DataFrame = None,
                columns_nan_replace_with: Dict[str, int] = None,
                inplace=True) -> pd.DataFrame:
        """
        Fill na in the requested columns and return where nan where found
        :param df_before: provided table
        :param columns_nan_replace_with: columns for which to replace nan
        :param inplace: modify the dataframe inside
        :return df_out: table without nan
        """
        if df_before is None:
            df_before = self.df_out
        if columns_nan_replace_with is None:
            columns_nan_replace_with = self.columns_nan_replace_with
        df_out = df_before.fillna(columns_nan_replace_with)
        if inplace:
            self.df_out = df_out
        return df_out

    def drop_duplicates(self, df_before: pd.DataFrame = None, columns_duplicates_check: List = None,
                        inplace=True) -> (pd.DataFrame, List):
        """
        Drop duplicated based on target columns
        :param df_before: provided table
        :param columns_duplicates_check: columns subset for duplicates checking
        :param inplace: implement changes and store information into the DataCleaning class
        :return df_out: table without the duplicates
        :return index_dropped: list of indexes dropped within the process
        """
        if df_before is None:
            df_before = self.df_out
        if columns_duplicates_check is None:
            columns_duplicates_check = self.columns_duplicates_check
        df_out = df_before.drop_duplicates(subset=columns_duplicates_check)
        index_dropped = df_before.index.difference(df_out.index).tolist()
        if inplace:
            self.df_out = df_out
            self.index_removed_by_process["duplicates_removed"]: List = index_dropped
        return df_out, index_dropped

    def get_outliers(self, df: pd.DataFrame = None, columns_outliers_ignore: List = None,
                     outliers_methods: List[str] = None, inplace=True) -> pd.DataFrame:
        """
        Call get_outliers_index() method to identify outliers
        :param df: table to be analysed
        :param columns_outliers_ignore: numerical columns to be ignored for outliers detection
        :param outliers_methods: see get_outliers_index() method
        :param inplace: implement changes and store information into the DataCleaning class
        :return df_outliers: table with information on detected outlier, see get_outliers_index() method
        """
        if df is None:
            df = self.df_out
        if columns_outliers_ignore is None:
            columns_outliers_ignore = self.columns_outliers_ignore
        if outliers_methods is None:
            outliers_methods = self.outliers_methods
        df_outliers = get_outliers_index(df, outliers_methods, columns_outliers_ignore)
        if inplace:
            self.outliers = df_outliers
        return df_outliers

    def drop_outliers(self, df_before: pd.DataFrame = None, columns_outliers_ignore: List = None,
                      outliers_methods: List[str] = None, inplace=True) -> (pd.DataFrame, List):
        """
        Drop outliers as identified through the get_outliers() method
        :param df_before: provided table
        :param columns_outliers_ignore: numerical columns to be ignored for outliers detection
        :param outliers_methods: see get_outliers_index() method
        :param inplace: implement changes and store information into the DataCleaning class
        :return df_out: table without the outliers
        :return index_dropped: indexes dropped within the process
        """
        if df_before is None:
            df_before = self.df_out
        if columns_outliers_ignore is None:
            columns_outliers_ignore = self.columns_outliers_ignore
        if outliers_methods is None:
            outliers_methods = self.outliers_methods
        df_outliers = self.get_outliers(df_before, columns_outliers_ignore, outliers_methods)
        index_dropped = []
        for index, row in df_outliers.iterrows():
            count, index = df_outliers.loc[index, ["count", "index"]]
            if count > 1:
                for i in index:
                    if i not in index_dropped:
                        index_dropped.append(i)
        df_out = df_before[~df_before.index.isin(index_dropped)]
        if inplace:
            self.index_removed_by_process["outliers_removed"]: List = index_dropped
            self.df_out = df_out
        return df_out, index_dropped
    

    def get_preprocessed_dataframe(self,
                                   database_columns: List[str] = DATABASE_COLUMNS,
                                   target: str = TARGET) -> (pd.DataFrame, pd.DataFrame):
        """
        Wrap-up method to clean the table and provide the main outputs in one line
        :param cleaned_csv_path: output path for the csv file
        :return df_out: cleaned table
        :return df_outliers: information about the outliers
        """
        print(f"Initial dataset, shape: {self.df_0.shape}")
        # aggregation to deal with many nan in facades_number
        # 11/12/20 aggregation transfered to features since values may be missed
        # self.df_out, aggregated_column_names = add_aggregated_columns(self.df_out, columns_to_replace=COLUMNS_TO_REPLACE)
        # self.columns_outliers_ignore += aggregated_column_names
        # print(f"Aggregated parameters replacing categorical ones, shape: {self.df_out.shape}")
        # 11/12/20 dropping transfered to features if needed (should happen in dataset)
        # self.df_out, index_dropped = self.drop_duplicates()
        #fill nan after replacing facades_number with grouping to avoid modelling issues
        #self.df_out = self.fill_na(self.df_out)
        #print(f"{len(index_dropped)} Dropped duplicates, shape: {self.df_out.shape}")
        df_outliers = self.get_outliers()
        #11/12/2020 adding features preprocessing before database
        #8/12/20 adding main features if not inserted
        for c in database_columns:
            if c not in self.df_out.columns.to_list():
                print(f'Database column {c} not in the dataframe')
        self.df_out = self.df_out.loc[:, database_columns]
        return self.df_out, df_outliers



#example table
table = {'hyperlink': ['https://www.immoweb.be/en/classified/house/for-sale/tournai/7500/9073897',
  'https://www.immoweb.be/en/classified/house/for-sale/wez-velvain/7620/8973818',
  'https://www.immoweb.be/en/classified/apartment-block/for-sale/jambes/5100/8989581',
  'https://www.immoweb.be/en/classified/house/for-sale/maldegem/9990/9073890',
  'https://www.immoweb.be/en/classified/house/for-sale/liege/4000/9073889',
  'https://www.immoweb.be/en/classified/house/for-sale/mons-jemappes/7012/9073874',
  'https://www.immoweb.be/en/classified/villa/for-sale/kalmthout/2920/9073873',
  'https://www.immoweb.be/en/classified/villa/for-sale/kontich/2550/8946075',
  'https://www.immoweb.be/en/classified/house/for-sale/diegem/1831/9073866',
  'https://www.immoweb.be/en/classified/chalet/for-sale/stekene/9190/9073843',
  'https://www.immoweb.be/en/classified/house/for-sale/roeselare/8800/9073862',
  'https://www.immoweb.be/en/classified/house/for-sale/boussu-hornu/7301/9073857',
  'https://www.immoweb.be/en/classified/villa/for-sale/waterloo/1410/9073852',
  'https://www.immoweb.be/en/classified/house/for-sale/minderhout/2323/9073851',
  'https://www.immoweb.be/en/classified/house/for-sale/antwerpen-deurne/2100/9073850',
  'https://www.immoweb.be/en/classified/villa/for-sale/goegnies-chaussee/7040/9073848',
  'https://www.immoweb.be/en/classified/house/for-sale/wachtebeke/9185/9073838',
  'https://www.immoweb.be/en/classified/apartment-block/for-sale/herbeumont/6887/9073840',
  'https://www.immoweb.be/en/classified/house/for-sale/de-haan/8420/8996975',
  'https://www.immoweb.be/en/classified/house/for-sale/wichelen/9260/9073814',
  'https://www.immoweb.be/en/classified/house/for-sale/landelies/6111/9073812',
  'https://www.immoweb.be/en/classified/house/for-sale/la-louviere/7100/9073811',
  'https://www.immoweb.be/en/classified/villa/for-sale/boussu/7300/9073800',
  'https://www.immoweb.be/en/classified/villa/for-sale/woluwe-saint-pierre/1150/8558092',
  'https://www.immoweb.be/en/classified/house/for-sale/zwevegem/8550/9073796',
  'https://www.immoweb.be/en/classified/house/for-sale/roesbrugge/8972/9073792',
  'https://www.immoweb.be/en/classified/house/for-sale/florenville/6820/9073788',
  'https://www.immoweb.be/en/classified/villa/for-sale/kruibeke/9150/9073785',
  'https://www.immoweb.be/en/classified/house/for-sale/aalter/9880/9073783',
  'https://www.immoweb.be/en/classified/house/for-sale/maldegem/9990/9073782',
  'https://www.immoweb.be/en/classified/apartment/for-sale/chaudfontaine/4050/9073896',
  'https://www.immoweb.be/en/classified/apartment/for-sale/brugge/8200/9073882',
  'https://www.immoweb.be/en/classified/apartment/for-sale/gent/9000/9073879',
  'https://www.immoweb.be/en/classified/apartment/for-sale/koningsloo/1800/9073877',
  'https://www.immoweb.be/en/classified/apartment/for-sale/koningsloo/1800/9073875',
  'https://www.immoweb.be/en/classified/apartment/for-sale/oostende/8400/9073869',
  'https://www.immoweb.be/en/classified/apartment/for-sale/herstal/4040/9073867',
  'https://www.immoweb.be/en/classified/penthouse/for-sale/herstal/4040/9073864',
  'https://www.immoweb.be/en/classified/apartment/for-sale/gent/9000/9073863',
  'https://www.immoweb.be/en/classified/duplex/for-sale/bruxelles-2/1020/9073821',
  'https://www.immoweb.be/en/classified/flat-studio/for-sale/oostduinkerke/8670/9073794',
  'https://www.immoweb.be/en/classified/ground-floor/for-sale/aalst/9300/9073804',
  'https://www.immoweb.be/en/classified/apartment/for-sale/schoten/2900/9073786',
  'https://www.immoweb.be/en/classified/apartment/for-sale/ganshoren/1083/9073780',
  'https://www.immoweb.be/en/classified/apartment/for-sale/schaerbeek/1030/9073779',
  'https://www.immoweb.be/en/classified/apartment/for-sale/kapellen/2950/9038348',
  'https://www.immoweb.be/en/classified/apartment/for-sale/oostende/8400/9073778',
  'https://www.immoweb.be/en/classified/duplex/for-sale/lier/2500/9073777',
  'https://www.immoweb.be/en/classified/apartment/for-sale/yvoir/5530/9073775',
  'https://www.immoweb.be/en/classified/apartment/for-sale/ciney/5590/9073774',
  'https://www.immoweb.be/en/classified/apartment/for-sale/woluwe-saint-lambert/1200/9073765',
  'https://www.immoweb.be/en/classified/apartment/for-sale/ixelles/1050/9073761',
  'https://www.immoweb.be/en/classified/apartment/for-sale/oostende/8400/9073754',
  'https://www.immoweb.be/en/classified/apartment/for-sale/knokke-centrum/8300/9073752',
  'https://www.immoweb.be/en/classified/apartment/for-sale/zellik/1731/9073738',
  'https://www.immoweb.be/en/classified/apartment/for-sale/antwerp/2060/9073745',
  'https://www.immoweb.be/en/classified/kot/for-sale/antwerp/2000/9073744',
  'https://www.immoweb.be/en/classified/apartment/for-sale/forest/1190/9073741',
  'https://www.immoweb.be/en/classified/apartment/for-sale/herstal/4040/9073729',
  'https://www.immoweb.be/en/classified/apartment/for-sale/molenbeek-st-jean/1080/9073724',
  'https://www.immoweb.be/en/classified/house/for-sale/koekelare/8680/8978234',
  'https://www.immoweb.be/en/classified/house/for-sale/st-gilles/1060/9073776',
  'https://www.immoweb.be/en/classified/villa/for-sale/wachtebeke/9185/8998871',
  'https://www.immoweb.be/en/classified/house/for-sale/jumet-(charleroi)/6040/9073773',
  'https://www.immoweb.be/en/classified/house/for-sale/beauraing/5570/9073772',
  'https://www.immoweb.be/en/classified/house/for-sale/waha/6900/9073771',
  'https://www.immoweb.be/en/classified/apartment-block/for-sale/jemelle/5580/9073770',
  'https://www.immoweb.be/en/classified/apartment-block/for-sale/cerfontaine/5630/9073769',
  'https://www.immoweb.be/en/classified/house/for-sale/scherpenheuvel/3270/9073760',
  'https://www.immoweb.be/en/classified/house/for-sale/ronse/9600/9073759',
  'https://www.immoweb.be/en/classified/house/for-sale/st-gillis-waas/9170/9073747',
  'https://www.immoweb.be/en/classified/house/for-sale/lier/2500/9073743',
  'https://www.immoweb.be/en/classified/house/for-sale/knokke/8300/9073742',
  'https://www.immoweb.be/en/classified/house/for-sale/couvin/5660/9073740',
  'https://www.immoweb.be/en/classified/house/for-sale/lichtervelde/8810/8710852',
  'https://www.immoweb.be/en/classified/house/for-sale/izegem/8870/9073735',
  'https://www.immoweb.be/en/classified/house/for-sale/ruien/9690/9073733',
  'https://www.immoweb.be/en/classified/house/for-sale/amonines/6997/9009418',
  'https://www.immoweb.be/en/classified/bungalow/for-sale/st-niklaas/9100/9073731',
  'https://www.immoweb.be/en/classified/house/for-sale/braine-lalleud/1420/9073728',
  'https://www.immoweb.be/en/classified/house/for-sale/auvelais/5060/9073721',
  'https://www.immoweb.be/en/classified/villa/for-sale/la-hulpe/3090/9073720',
  'https://www.immoweb.be/en/classified/house/for-sale/auvelais/5060/9073719',
  'https://www.immoweb.be/en/classified/house/for-sale/wagnelee/6223/9073718',
  'https://www.immoweb.be/en/classified/house/for-sale/auvelais/5060/9073717',
  'https://www.immoweb.be/en/classified/bungalow/for-sale/tielrode/9140/9073716',
  'https://www.immoweb.be/en/classified/house/for-sale/blankenberge/8370/9073714',
  'https://www.immoweb.be/en/classified/house/for-sale/turnhout/2300/9073713',
  'https://www.immoweb.be/en/classified/apartment-block/for-sale/liege/4020/9073705',
  'https://www.immoweb.be/en/classified/apartment-block/for-sale/jette/1090/9073702',
  'https://www.immoweb.be/en/classified/apartment/for-sale/hasselt/3500/9073723',
  'https://www.immoweb.be/en/classified/apartment/for-sale/halle/1500/9073700',
  'https://www.immoweb.be/en/classified/flat-studio/for-sale/middelkerke/8430/8967787',
  'https://www.immoweb.be/en/classified/apartment/for-sale/drogenbos/1620/9073699',
  'https://www.immoweb.be/en/classified/apartment/for-sale/anderlecht/1070/9073696',
  'https://www.immoweb.be/en/classified/apartment/for-sale/wommelgem/2160/9073694',
  'https://www.immoweb.be/en/classified/apartment/for-sale/blankenberge/8370/9073692',
  'https://www.immoweb.be/en/classified/apartment/for-sale/mortsel/2640/9073688',
  'https://www.immoweb.be/en/classified/apartment/for-sale/deurne/2100/9002434',
  'https://www.immoweb.be/en/classified/apartment/for-sale/uccle/1180/9073684',
  'https://www.immoweb.be/en/classified/apartment/for-sale/molenbeek-saint-jean/1080/9073682',
  'https://www.immoweb.be/en/classified/apartment/for-sale/falisolle/5060/9005838',
  'https://www.immoweb.be/en/classified/apartment/for-sale/tamines/5060/7792350',
  'https://www.immoweb.be/en/classified/apartment/for-sale/molenbeek-saint-jean/1080/9073678',
  'https://www.immoweb.be/en/classified/ground-floor/for-sale/borgerhout/2140/9073669',
  'https://www.immoweb.be/en/classified/duplex/for-sale/borgerhout/2140/9073668',
  'https://www.immoweb.be/en/classified/apartment/for-sale/borgerhout/2140/9073666',
  'https://www.immoweb.be/en/classified/duplex/for-sale/heist/8301/9073665',
  'https://www.immoweb.be/en/classified/apartment/for-sale/forest/1190/9073658',
  'https://www.immoweb.be/en/classified/apartment/for-sale/bruxelles/1000/9073657',
  'https://www.immoweb.be/en/classified/apartment/for-sale/bruxelles/1000/9073656',
  'https://www.immoweb.be/en/classified/apartment/for-sale/forest/1190/9073654',
  'https://www.immoweb.be/en/classified/apartment/for-sale/molenbeek-saint-jean/1080/9073653',
  'https://www.immoweb.be/en/classified/apartment/for-sale/bruxelles/1000/9073650',
  'https://www.immoweb.be/en/classified/flat-studio/for-sale/middelkerke/8430/8967706',
  'https://www.immoweb.be/en/classified/apartment/for-sale/namur/5000/9073635',
  'https://www.immoweb.be/en/classified/apartment/for-sale/oostduinkerke/8670/9073620',
  'https://www.immoweb.be/en/classified/apartment/for-sale/harelbeke/8530/8971775',
  'https://www.immoweb.be/en/classified/flat-studio/for-sale/oostende/8400/9073614',
  'https://www.immoweb.be/en/classified/duplex/for-sale/sint-niklaas/9100/9073609'],
 'locality': ['tournai',
  'wez-velvain',
  'jambes',
  'maldegem',
  'liege',
  'mons-jemappes',
  'kalmthout',
  'kontich',
  'diegem',
  'stekene',
  'roeselare',
  'boussu-hornu',
  'waterloo',
  'minderhout',
  'antwerpen-deurne',
  'goegnies-chaussee',
  'wachtebeke',
  'herbeumont',
  'de-haan',
  'wichelen',
  'landelies',
  'la-louviere',
  'boussu',
  'woluwe-saint-pierre',
  'zwevegem',
  'roesbrugge',
  'florenville',
  'kruibeke',
  'aalter',
  'maldegem',
  'chaudfontaine',
  'brugge',
  'gent',
  'koningsloo',
  'koningsloo',
  'oostende',
  'herstal',
  'herstal',
  'gent',
  'bruxelles-2',
  'oostduinkerke',
  'aalst',
  'schoten',
  'ganshoren',
  'schaerbeek',
  'kapellen',
  'oostende',
  'lier',
  'yvoir',
  'ciney',
  'woluwe-saint-lambert',
  'ixelles',
  'oostende',
  'knokke-centrum',
  'zellik',
  'antwerp',
  'antwerp',
  'forest',
  'herstal',
  'molenbeek-st-jean',
  'koekelare',
  'st-gilles',
  'wachtebeke',
  'jumet-(charleroi)',
  'beauraing',
  'waha',
  'jemelle',
  'cerfontaine',
  'scherpenheuvel',
  'ronse',
  'st-gillis-waas',
  'lier',
  'knokke',
  'couvin',
  'lichtervelde',
  'izegem',
  'ruien',
  'amonines',
  'st-niklaas',
  'braine-lalleud',
  'auvelais',
  'la-hulpe',
  'auvelais',
  'wagnelee',
  'auvelais',
  'tielrode',
  'blankenberge',
  'turnhout',
  'liege',
  'jette',
  'hasselt',
  'halle',
  'middelkerke',
  'drogenbos',
  'anderlecht',
  'wommelgem',
  'blankenberge',
  'mortsel',
  'deurne',
  'uccle',
  'molenbeek-saint-jean',
  'falisolle',
  'tamines',
  'molenbeek-saint-jean',
  'borgerhout',
  'borgerhout',
  'borgerhout',
  'heist',
  'forest',
  'bruxelles',
  'bruxelles',
  'forest',
  'molenbeek-saint-jean',
  'bruxelles',
  'middelkerke',
  'namur',
  'oostduinkerke',
  'harelbeke',
  'oostende',
  'sint-niklaas'],
 'postcode': ['7500',
  '7620',
  '5100',
  '9990',
  '4000',
  '7012',
  '2920',
  '2550',
  '1831',
  '9190',
  '8800',
  '7301',
  '1410',
  '2323',
  '2100',
  '7040',
  '9185',
  '6887',
  '8420',
  '9260',
  '6111',
  '7100',
  '7300',
  '1150',
  '8550',
  '8972',
  '6820',
  '9150',
  '9880',
  '9990',
  '4050',
  '8200',
  '9000',
  '1800',
  '1800',
  '8400',
  '4040',
  '4040',
  '9000',
  '1020',
  '8670',
  '9300',
  '2900',
  '1083',
  '1030',
  '2950',
  '8400',
  '2500',
  '5530',
  '5590',
  '1200',
  '1050',
  '8400',
  '8300',
  '1731',
  '2060',
  '2000',
  '1190',
  '4040',
  '1080',
  '8680',
  '1060',
  '9185',
  '6040',
  '5570',
  '6900',
  '5580',
  '5630',
  '3270',
  '9600',
  '9170',
  '2500',
  '8300',
  '5660',
  '8810',
  '8870',
  '9690',
  '6997',
  '9100',
  '1420',
  '5060',
  '3090',
  '5060',
  '6223',
  '5060',
  '9140',
  '8370',
  '2300',
  '4020',
  '1090',
  '3500',
  '1500',
  '8430',
  '1620',
  '1070',
  '2160',
  '8370',
  '2640',
  '2100',
  '1180',
  '1080',
  '5060',
  '5060',
  '1080',
  '2140',
  '2140',
  '2140',
  '8301',
  '1190',
  '1000',
  '1000',
  '1190',
  '1080',
  '1000',
  '8430',
  '5000',
  '8670',
  '8530',
  '8400',
  '9100'],
 'house_is': [True,
  True,
  True,
  True,
  True,
  True,
  True,
  True,
  True,
  True,
  True,
  True,
  True,
  True,
  True,
  True,
  True,
  True,
  True,
  True,
  True,
  True,
  True,
  True,
  True,
  True,
  True,
  True,
  True,
  True,
  False,
  False,
  False,
  False,
  False,
  False,
  False,
  False,
  False,
  False,
  False,
  False,
  False,
  False,
  False,
  False,
  False,
  False,
  False,
  False,
  False,
  False,
  False,
  False,
  False,
  False,
  False,
  False,
  False,
  False,
  True,
  True,
  True,
  True,
  True,
  True,
  True,
  True,
  True,
  True,
  True,
  True,
  True,
  True,
  True,
  True,
  True,
  True,
  True,
  True,
  True,
  True,
  True,
  True,
  True,
  True,
  True,
  True,
  True,
  True,
  False,
  False,
  False,
  False,
  False,
  False,
  False,
  False,
  False,
  False,
  False,
  False,
  False,
  False,
  False,
  False,
  False,
  False,
  False,
  False,
  False,
  False,
  False,
  False,
  False,
  False,
  False,
  False,
  False,
  False],
 'property_subtype': ['house',
  'house',
  'apartment-block',
  'house',
  'house',
  'house',
  'villa',
  'villa',
  'house',
  'chalet',
  'house',
  'house',
  'villa',
  'house',
  'house',
  'villa',
  'house',
  'apartment-block',
  'house',
  'house',
  'house',
  'house',
  'villa',
  'villa',
  'house',
  'house',
  'house',
  'villa',
  'house',
  'house',
  'apartment',
  'apartment',
  'apartment',
  'apartment',
  'apartment',
  'apartment',
  'apartment',
  'penthouse',
  'apartment',
  'duplex',
  'flat-studio',
  'ground-floor',
  'apartment',
  'apartment',
  'apartment',
  'apartment',
  'apartment',
  'duplex',
  'apartment',
  'apartment',
  'apartment',
  'apartment',
  'apartment',
  'apartment',
  'apartment',
  'apartment',
  'kot',
  'apartment',
  'apartment',
  'apartment',
  'house',
  'house',
  'villa',
  'house',
  'house',
  'house',
  'apartment-block',
  'apartment-block',
  'house',
  'house',
  'house',
  'house',
  'house',
  'house',
  'house',
  'house',
  'house',
  'house',
  'bungalow',
  'house',
  'house',
  'villa',
  'house',
  'house',
  'house',
  'bungalow',
  'house',
  'house',
  'apartment-block',
  'apartment-block',
  'apartment',
  'apartment',
  'flat-studio',
  'apartment',
  'apartment',
  'apartment',
  'apartment',
  'apartment',
  'apartment',
  'apartment',
  'apartment',
  'apartment',
  'apartment',
  'apartment',
  'ground-floor',
  'duplex',
  'apartment',
  'duplex',
  'apartment',
  'apartment',
  'apartment',
  'apartment',
  'apartment',
  'apartment',
  'flat-studio',
  'apartment',
  'apartment',
  'apartment',
  'flat-studio',
  'duplex'],
 'price': [123000,
  199000,
  1000000,
  None,
  204500,
  55000,
  1095000,
  495000,
  340000,
  147000,
  225000,
  75000,
  615000,
  698000,
  299000,
  180000,
  429000,
  230000,
  279000,
  339000,
  255000,
  80000,
  260000,
  2800000,
  259000,
  145000,
  325000,
  610000,
  849000,
  320000,
  220000,
  320000,
  None,
  185000,
  230000,
  365000,
  203500,
  201500,
  325000,
  235000,
  149000,
  None,
  182000,
  275000,
  265000,
  213000,
  140000,
  319000,
  79000,
  239000,
  255000,
  395000,
  335000,
  495000,
  199000,
  159000,
  121000,
  440000,
  199000,
  220000,
  199000,
  569000,
  479000,
  95000,
  279000,
  160000,
  199000,
  260000,
  269000,
  145000,
  289000,
  188000,
  599000,
  149000,
  190000,
  233500,
  446594,
  149000,
  599000,
  325000,
  165000,
  685000,
  165000,
  340000,
  165000,
  195000,
  295000,
  298000,
  350000,
  385000,
  474950,
  415000,
  85000,
  195000,
  125000,
  310000,
  259000,
  219000,
  189000,
  1145000,
  255000,
  169000,
  99000,
  229000,
  299000,
  299000,
  299000,
  525000,
  330000,
  455000,
  325000,
  440000,
  269000,
  340000,
  85000,
  250000,
  165000,
  159000,
  145000,
  239000],
 'sale': ['',
  '',
  '',
  '',
  '',
  '',
  '',
  '',
  '',
  '',
  '',
  '',
  '',
  '',
  '',
  '',
  '',
  '',
  '',
  '',
  '',
  '',
  '',
  '',
  '',
  '',
  '',
  '',
  '',
  '',
  '',
  '',
  '',
  '',
  '',
  '',
  '',
  '',
  '',
  '',
  '',
  '',
  '',
  '',
  '',
  '',
  '',
  '',
  '',
  '',
  '',
  '',
  '',
  '',
  '',
  '',
  '',
  '',
  '',
  '',
  '',
  '',
  '',
  '',
  '',
  '',
  '',
  '',
  '',
  '',
  '',
  '',
  '',
  '',
  '',
  '',
  '',
  '',
  '',
  '',
  '',
  '',
  '',
  '',
  '',
  '',
  '',
  '',
  '',
  '',
  '',
  '',
  '',
  '',
  '',
  '',
  '',
  '',
  '',
  '',
  '',
  '',
  '',
  '',
  '',
  '',
  '',
  '',
  '',
  '',
  '',
  '',
  '',
  '',
  '',
  '',
  '',
  '',
  '',
  ''],
 'rooms_number': ['3',
  '2',
  '11',
  '2',
  '4',
  '2',
  '5',
  '4',
  '3',
  '2',
  '3',
  '2',
  '4',
  '4',
  '2',
  '3',
  '3',
  '6',
  '4',
  '4',
  '3',
  '3',
  '3',
  '6',
  '3',
  '7',
  '5',
  '3',
  '5',
  '3',
  '2',
  '2',
  '2',
  '2',
  '2',
  '3',
  '2',
  '2',
  '2',
  '2',
  '1',
  '2',
  '2',
  '2',
  '3',
  '2',
  '1',
  '2',
  '1',
  '3',
  '2',
  '2',
  '2',
  '2',
  '2',
  '1',
  '1',
  '4',
  '1',
  '3',
  '5',
  '6',
  '4',
  '2',
  '5',
  '5',
  '1',
  '5',
  '3',
  '3',
  '2',
  '3',
  '2',
  '4',
  '3',
  '3',
  '4',
  '4',
  '2',
  '3',
  '3',
  '4',
  '3',
  '3',
  '3',
  '2',
  '4',
  '3',
  None,
  '4',
  '2',
  '3',
  None,
  '2',
  '1',
  '3',
  '2',
  '2',
  '2',
  '3',
  '3',
  '2',
  '3',
  '2',
  '3',
  '3',
  '3',
  '3',
  '2',
  '5',
  '2',
  '2',
  '3',
  '2',
  None,
  '2',
  '1',
  '2',
  None,
  '3'],
 'area': [None,
  '115',
  None,
  None,
  '150',
  '85',
  '438',
  '229',
  None,
  None,
  None,
  '108',
  '221',
  '298',
  '175',
  None,
  '157',
  '225',
  '200',
  '200',
  '175',
  '125',
  None,
  '700',
  None,
  '442',
  None,
  '166',
  '240',
  '120',
  '87',
  '78',
  None,
  '80',
  '103',
  '120',
  '96',
  '82',
  '103',
  '90',
  '30',
  None,
  '97',
  None,
  None,
  '74',
  None,
  '164',
  '68',
  '142',
  None,
  '85',
  '98',
  '110',
  '90',
  '65',
  '18',
  '182',
  '69',
  '85',
  None,
  '200',
  '259',
  '58',
  '288',
  '265',
  '145',
  '400',
  '160',
  None,
  None,
  None,
  '108',
  '135',
  '120',
  None,
  '296',
  '142',
  '200',
  '130',
  None,
  '270',
  None,
  None,
  None,
  None,
  None,
  '162',
  '189',
  '215',
  '145',
  '140',
  '35',
  '70',
  '54',
  '129',
  '71',
  '85',
  '116',
  '151',
  '113',
  None,
  None,
  '87',
  '156',
  '156',
  '156',
  '157',
  '93',
  '165',
  '100',
  '220',
  '120',
  '90',
  '35',
  '72',
  '57',
  '115',
  '39',
  '123'],
 'kitchen_has': [False,
  True,
  False,
  False,
  True,
  False,
  True,
  True,
  True,
  False,
  True,
  False,
  True,
  False,
  False,
  False,
  True,
  False,
  True,
  False,
  True,
  True,
  True,
  False,
  True,
  True,
  True,
  True,
  True,
  True,
  True,
  True,
  False,
  False,
  False,
  True,
  True,
  True,
  True,
  True,
  False,
  False,
  True,
  True,
  True,
  True,
  False,
  True,
  False,
  False,
  False,
  True,
  True,
  True,
  True,
  True,
  True,
  False,
  True,
  True,
  True,
  True,
  True,
  True,
  True,
  True,
  True,
  True,
  True,
  True,
  False,
  False,
  True,
  True,
  False,
  False,
  False,
  True,
  True,
  True,
  True,
  True,
  True,
  True,
  True,
  True,
  False,
  True,
  True,
  True,
  True,
  True,
  True,
  True,
  True,
  False,
  False,
  True,
  False,
  True,
  True,
  False,
  False,
  True,
  True,
  True,
  True,
  True,
  False,
  True,
  True,
  False,
  False,
  True,
  True,
  True,
  True,
  True,
  True,
  False],
 'furnished': [False,
  False,
  False,
  False,
  False,
  False,
  False,
  False,
  False,
  True,
  False,
  False,
  False,
  False,
  False,
  False,
  False,
  False,
  False,
  False,
  False,
  False,
  False,
  False,
  False,
  False,
  False,
  False,
  False,
  False,
  False,
  False,
  False,
  False,
  False,
  False,
  False,
  False,
  False,
  False,
  False,
  False,
  False,
  False,
  False,
  False,
  False,
  False,
  False,
  False,
  False,
  False,
  False,
  False,
  False,
  False,
  False,
  False,
  False,
  False,
  False,
  False,
  False,
  False,
  False,
  False,
  False,
  False,
  False,
  False,
  False,
  False,
  False,
  False,
  False,
  False,
  False,
  False,
  False,
  False,
  False,
  False,
  False,
  False,
  False,
  False,
  False,
  False,
  False,
  False,
  False,
  False,
  True,
  False,
  False,
  False,
  False,
  False,
  False,
  False,
  False,
  False,
  False,
  False,
  False,
  False,
  False,
  False,
  False,
  False,
  False,
  False,
  False,
  False,
  True,
  False,
  False,
  False,
  False,
  False],
 'open_fire': [False,
  False,
  False,
  False,
  False,
  False,
  False,
  False,
  False,
  False,
  False,
  False,
  False,
  False,
  False,
  False,
  False,
  False,
  False,
  False,
  False,
  False,
  False,
  False,
  False,
  False,
  False,
  False,
  False,
  False,
  False,
  False,
  False,
  False,
  False,
  False,
  False,
  False,
  False,
  False,
  False,
  False,
  False,
  False,
  False,
  False,
  False,
  False,
  False,
  False,
  False,
  False,
  False,
  False,
  False,
  False,
  False,
  False,
  False,
  False,
  False,
  False,
  False,
  False,
  False,
  False,
  False,
  False,
  False,
  False,
  False,
  False,
  False,
  False,
  False,
  False,
  False,
  False,
  False,
  False,
  False,
  False,
  False,
  False,
  False,
  False,
  False,
  False,
  False,
  False,
  False,
  False,
  False,
  False,
  False,
  False,
  False,
  False,
  False,
  False,
  False,
  False,
  False,
  False,
  False,
  False,
  False,
  False,
  False,
  False,
  False,
  False,
  False,
  False,
  False,
  False,
  False,
  False,
  False,
  False],
 'terrace': [True,
  True,
  False,
  False,
  True,
  False,
  True,
  True,
  False,
  False,
  True,
  False,
  True,
  True,
  True,
  True,
  False,
  False,
  True,
  False,
  True,
  False,
  False,
  True,
  True,
  True,
  True,
  True,
  False,
  False,
  True,
  True,
  False,
  False,
  False,
  True,
  True,
  True,
  True,
  True,
  False,
  False,
  False,
  True,
  True,
  True,
  False,
  True,
  False,
  False,
  True,
  False,
  True,
  True,
  True,
  False,
  True,
  False,
  True,
  True,
  True,
  True,
  True,
  False,
  False,
  False,
  True,
  False,
  False,
  False,
  False,
  True,
  True,
  True,
  True,
  True,
  False,
  False,
  True,
  True,
  False,
  True,
  False,
  True,
  False,
  False,
  False,
  False,
  True,
  True,
  False,
  True,
  True,
  False,
  False,
  True,
  True,
  True,
  True,
  True,
  True,
  True,
  False,
  True,
  True,
  True,
  True,
  False,
  True,
  True,
  False,
  True,
  True,
  True,
  True,
  True,
  True,
  False,
  True,
  True],
 'terrace_area': ['15',
  '31',
  None,
  None,
  '40',
  None,
  None,
  '10',
  None,
  None,
  '15',
  None,
  None,
  '100',
  None,
  None,
  None,
  None,
  None,
  None,
  None,
  None,
  None,
  '100',
  None,
  None,
  None,
  None,
  None,
  None,
  '16',
  None,
  None,
  None,
  None,
  None,
  '8',
  '14',
  '4',
  '10',
  None,
  None,
  None,
  None,
  None,
  '8',
  None,
  '15',
  None,
  None,
  None,
  None,
  '32',
  None,
  '7',
  None,
  None,
  None,
  '5',
  None,
  None,
  '5',
  '45',
  None,
  None,
  None,
  '20',
  None,
  None,
  None,
  None,
  None,
  None,
  None,
  None,
  None,
  None,
  None,
  None,
  None,
  None,
  '40',
  None,
  None,
  None,
  None,
  None,
  None,
  '33',
  None,
  None,
  '26',
  None,
  None,
  None,
  '21',
  None,
  None,
  '9',
  None,
  '7',
  None,
  None,
  '10',
  '19',
  '19',
  '19',
  None,
  '6',
  '5',
  None,
  '15',
  '75',
  '3',
  None,
  '5',
  None,
  None,
  '10',
  None],
 'garden': [True,
  True,
  False,
  False,
  True,
  False,
  True,
  True,
  True,
  False,
  True,
  False,
  True,
  False,
  False,
  False,
  True,
  False,
  True,
  False,
  False,
  True,
  False,
  True,
  True,
  True,
  False,
  False,
  False,
  False,
  False,
  False,
  False,
  False,
  False,
  False,
  False,
  False,
  False,
  True,
  False,
  False,
  False,
  False,
  False,
  False,
  False,
  False,
  False,
  True,
  False,
  False,
  False,
  False,
  False,
  False,
  False,
  False,
  False,
  False,
  False,
  False,
  True,
  False,
  False,
  False,
  True,
  True,
  True,
  False,
  False,
  False,
  False,
  True,
  False,
  False,
  False,
  True,
  True,
  True,
  True,
  True,
  True,
  False,
  True,
  False,
  False,
  False,
  False,
  False,
  False,
  False,
  False,
  False,
  False,
  False,
  False,
  False,
  False,
  False,
  False,
  False,
  False,
  False,
  True,
  True,
  True,
  False,
  False,
  False,
  False,
  False,
  False,
  False,
  False,
  False,
  False,
  False,
  False,
  True],
 'garden_area': ['40',
  '500',
  None,
  None,
  '32',
  None,
  '1535',
  '880',
  None,
  None,
  None,
  None,
  None,
  None,
  None,
  None,
  None,
  None,
  None,
  None,
  None,
  '39',
  None,
  '1500',
  '368',
  None,
  None,
  None,
  None,
  None,
  None,
  None,
  None,
  None,
  None,
  None,
  None,
  None,
  None,
  '25',
  None,
  None,
  None,
  None,
  None,
  None,
  None,
  None,
  None,
  None,
  None,
  None,
  None,
  None,
  None,
  None,
  None,
  None,
  None,
  None,
  None,
  None,
  '806',
  None,
  None,
  None,
  None,
  None,
  None,
  None,
  None,
  None,
  None,
  '70',
  None,
  None,
  None,
  '702',
  None,
  None,
  None,
  None,
  None,
  None,
  None,
  None,
  None,
  None,
  None,
  None,
  None,
  None,
  None,
  None,
  None,
  None,
  None,
  None,
  None,
  None,
  None,
  None,
  None,
  None,
  '28',
  '28',
  '28',
  None,
  None,
  None,
  None,
  None,
  None,
  None,
  None,
  None,
  None,
  None,
  None,
  None],
 'land_surface': [None,
  None,
  None,
  None,
  None,
  None,
  None,
  None,
  None,
  None,
  None,
  None,
  None,
  None,
  None,
  None,
  None,
  None,
  None,
  None,
  None,
  None,
  None,
  None,
  None,
  None,
  None,
  None,
  None,
  None,
  None,
  None,
  None,
  None,
  None,
  None,
  None,
  None,
  None,
  None,
  None,
  None,
  None,
  None,
  None,
  None,
  None,
  None,
  None,
  None,
  None,
  None,
  None,
  None,
  None,
  None,
  None,
  None,
  None,
  None,
  None,
  None,
  None,
  None,
  None,
  None,
  None,
  None,
  None,
  None,
  None,
  None,
  None,
  None,
  None,
  None,
  None,
  None,
  None,
  None,
  None,
  None,
  None,
  None,
  None,
  None,
  None,
  None,
  None,
  None,
  None,
  None,
  None,
  None,
  None,
  None,
  None,
  None,
  None,
  None,
  None,
  None,
  None,
  None,
  None,
  None,
  None,
  None,
  None,
  None,
  None,
  None,
  None,
  None,
  None,
  None,
  None,
  None,
  None,
  None],
 'land_plot_surface': [None,
  '1000',
  '174',
  '755',
  '172',
  '100',
  '1973',
  '1147',
  '106',
  '1380',
  '320',
  '131',
  '593',
  '6985',
  '180',
  '750',
  '357',
  '279',
  '395',
  '268',
  None,
  '410',
  None,
  '2000',
  '460',
  '1119000',
  '1637',
  '401',
  '15608',
  '407',
  None,
  None,
  None,
  None,
  None,
  None,
  None,
  None,
  None,
  None,
  None,
  None,
  None,
  None,
  None,
  None,
  None,
  None,
  None,
  None,
  None,
  None,
  None,
  None,
  None,
  None,
  None,
  None,
  None,
  None,
  '165',
  '60',
  '1000',
  '360',
  '315',
  '833',
  '300',
  '296',
  '215',
  '450',
  '290',
  '122',
  None,
  '130',
  '223',
  '388',
  '1371',
  '702',
  '2616',
  '383',
  None,
  '1628',
  None,
  '993',
  None,
  '435',
  '100',
  None,
  '122',
  '90',
  None,
  None,
  None,
  None,
  None,
  None,
  None,
  None,
  None,
  None,
  None,
  None,
  None,
  None,
  None,
  None,
  None,
  None,
  None,
  None,
  None,
  None,
  None,
  None,
  None,
  None,
  None,
  None,
  None,
  None],
 'facades_number': [None,
  None,
  None,
  None,
  None,
  None,
  None,
  None,
  None,
  None,
  None,
  None,
  None,
  None,
  None,
  None,
  None,
  None,
  None,
  None,
  None,
  None,
  None,
  None,
  None,
  None,
  None,
  None,
  None,
  None,
  None,
  None,
  None,
  None,
  None,
  None,
  None,
  None,
  None,
  None,
  None,
  None,
  None,
  None,
  None,
  None,
  None,
  None,
  None,
  None,
  None,
  None,
  None,
  None,
  None,
  None,
  None,
  None,
  None,
  None,
  None,
  None,
  None,
  None,
  None,
  None,
  None,
  None,
  None,
  None,
  None,
  None,
  None,
  None,
  None,
  None,
  None,
  None,
  None,
  None,
  None,
  None,
  None,
  None,
  None,
  None,
  None,
  None,
  None,
  None,
  None,
  None,
  None,
  None,
  None,
  None,
  None,
  None,
  None,
  None,
  None,
  None,
  None,
  None,
  None,
  None,
  None,
  None,
  None,
  None,
  None,
  None,
  None,
  None,
  None,
  None,
  None,
  None,
  None,
  None],
 'swimming_pool_has': [False,
  False,
  False,
  False,
  False,
  False,
  True,
  False,
  False,
  False,
  False,
  False,
  False,
  False,
  False,
  False,
  False,
  False,
  False,
  False,
  False,
  False,
  False,
  True,
  False,
  False,
  False,
  False,
  False,
  False,
  False,
  False,
  False,
  False,
  False,
  False,
  False,
  False,
  False,
  False,
  False,
  False,
  False,
  False,
  False,
  False,
  False,
  False,
  False,
  False,
  False,
  False,
  False,
  False,
  False,
  False,
  False,
  False,
  False,
  False,
  False,
  False,
  True,
  False,
  True,
  False,
  False,
  False,
  False,
  False,
  False,
  False,
  False,
  False,
  False,
  False,
  False,
  False,
  False,
  False,
  False,
  False,
  False,
  False,
  False,
  False,
  False,
  False,
  False,
  False,
  False,
  False,
  False,
  False,
  False,
  False,
  False,
  False,
  False,
  False,
  False,
  False,
  False,
  False,
  False,
  False,
  False,
  False,
  False,
  False,
  False,
  False,
  False,
  False,
  False,
  False,
  False,
  False,
  False,
  False]}


_VALUES_FORMAT = dict(hyperlink='str', locality='str', type_of_property='str', postcode='int',
                      garden='yn', facades_number='int')

"""
_VALUES_FORMAT = dict(hyperlink='str', locality='str', postcode='int', house_is='yn', property_subtype='str',
                      price='int', sale='str', rooms_number='int', area='int', kitchen_has='yn', furnished='yn',
                      open_fire='yn', terrace='yn', terrace_area='int', garden='yn', garden_area='int',
                      land_surface='int', land_plot_surface='int', facades_number='int', swimming_pool_has='yn')
"""



def clean_for_database(table: dict) -> pd.DataFrame:
    df = pd.DataFrame(table)
    sdc = SalesDataCleaner(sales_data=df)
    sdc.clean()
    df = sdc.sales_data
    df.rename(columns= RENAME_FOR_DATABASE, inplace= True)
    dc = DataCleaning(dataframe=df)
    df, df_outliers = dc.get_preprocessed_dataframe()
    return df, df_outliers
